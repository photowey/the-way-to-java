# `MySQL`

## 1.优化

- 避免不需要的列
  - 不 `SELECT * FROM table_name`
- 分页优化
  - 延迟关联
  - 书签
- 索引优化
  - 索引覆盖
  - 避免使用 `!=`
  - 适当使用前缀索引
  - 避免列上函数运算
  - 正确的使用联合索引
- `JOIN` 优化
  - 优化子查询
  - 小表驱动达标
  - 适当增加冗余字段
  - 避免 `JOIN` 太多表
- 排序优化
  - 利用索引扫描做排序
- `UNION` 优化
  - 条件下推
  - `UNION ALL` 替代 `UNION`



### 1.1.`SQL` 示例

```sql
SELECT e.id, e.name, d.details
FROM (
    SELECT id
    FROM employees
    ORDER BY id
    LIMIT 1000, 20
) AS sub
JOIN employees e ON sub.id = e.id
JOIN department d ON e.department_id = d.id;
```

```sql
SELECT id, name
FROM users
WHERE id > last_page_max_id  -- 假设 last_page_max_id 是上一页最后一行的 ID
ORDER BY id
LIMIT 20;
```



## 2.执行计划

- `id`
- `select_type`
  - `SIMPLE`
  - `PRIMARY`
  - `SUBQUERY`
- `table`
- `type`
  - `system`
  - `const`
    - 表示查询时命中 `primary key` 主键或者 `unique` 唯一索引,或者被连接的部分是一个常量(`const`) 值
  - `eq_ref`
    - 查询时命中主键 `primary key` 或者 `unique key` 索引
  - `ref_or_null`
  - `index_merge`
    - 使用了索引合并优化方法,查询使用了两个以上的索引
  - `unique_subquery`
  - `index_subquery`
  - `range`
  - `index`
    - 遍历索引树
  - `ALL`
- `possible_keys`
- `keys`
- `ken_len`
- `ref`
- `rows`
- `extra`
  - `Using index`
  - `Using where`
  - `Using temporary`



## 3.索引

- 功能分类

  - 主键索引
  - 唯一索引
  - 普通索引
  - 联合索引
  - 全文检索
  - 空间索引(5.7+)
    - `OpenGIS`

- 数据结构

  - `B+` 索引

    - ```http
      https://mp.weixin.qq.com/s/muOwXKNTvPjXjrLsFRveIw
      # 为什么索引是 B+ 树 数据结构
      ```

    - 

  - 哈希索引

- 存储位置

  - 聚簇索引
  
    - 聚集索引就是以主键创建的索引,在叶子节点存储的是表中的数据（`Innodb`存储引擎）
  
  - 非聚簇索引
  
    - 非聚集索引就是以非主键创建的索引,在叶子节点存储的是主键和索引列（`Innodb`存储引擎）
  
    

### 3.1.注意事项

- 现在合适的列作为索引
  - 经常作为查询条件(`WHERE` 子句),排序条件(`ORDER BY` 子句), 分组条件(`GROUP BY` 子句)的列是好的候选
  - 区分度低的字段 **不建议** 建立索引
  - 频繁更新的字段 **不建议** 作为主键或索引
  - 无序的值 **不建议** 作为索引(身份证, `UUID`…), 当主键具有不确定性, 或造成叶子节点频繁分裂,出现磁盘存储的碎片化
- 避免过多的索引
  - 每个索引都需要占用额外的磁盘空间
  - 更新表（`INSERT`、`UPDATE`、`DELETE` 操作）时,所有的索引都需要被更新
  - 维护索引文件需要成本,还会导致页分裂, `IO` 次数增多
- 利用前缀索引和索引列顺序
  - 对于字符串类型的列,可以考虑使用前缀索引来减少索引大小
  - 在创建复合索引时,应该根据查询条件将最常用作过来条件的列放在前面



### 3.2.索引失效

- 查询条件包含 `OR`, 可能会导致索引失效
- 隐式转换,导致索引失效
- `LIKE` 通配符,可能导致索引失效
- 联合索引-查询条件列不是索引的第一列,导致索引失效
- 在索引列使用 `MySQL` 内置函数,导致索引失效
- 对索引列运算(`+`,`-`,`*`,`/` …),导致索引失效
- 在索引列使用 `!=` 或 `NOT IN`, 可能导致索引失效
- 在索引列上使用 `IS NULL`, `IS NOT NULL`,可能导致索引失效
- 左,右连接关联字段的编码格式不一样,可能导致索引失效
- 如果优化器认为全表扫描要比使用索引快,则不使用索引



### 3.3.不适合索引

- 数据量比较少的表
- 更新比较频繁的字段
- 离散度低的字段



### 3.4.索引选择 `B+` 树原因

> `InnoDB` 默认: 页大小 16 `KB`

- 更高效的磁盘 `I/O`
  - 减少磁盘寻道时间
  - 减少页加载次数
- 支持范围查询
- 查询性能稳定
  - 所有的查询操作都有着相同的访问深度,查询性能稳定



-- -

总结

1. `B+`树索引在空间和时间上都有代价,所以没事儿别瞎建索引
2. `B+`树索引适用于下边这些情况
   - 1.全值匹配
   - 2.匹配左边的列
   - 3.匹配范围值
   - 4.匹配某一列并范围匹配另外一列
   - 5.用于排序
   - 6.用于分组
3. 在使用索引时需要注意下边这些事项
   - 1.只为用于搜索、排序或分组的列创建索引
   - 2.为列的基数大的列创建索引
   - 3.索引列的类型尽量小
   - 4.可以只对字符串值的前缀建立索引
   - 5.只有索引列在比较表达式中单独出现才可以适用索引
   - 6.为了尽可能少的让`聚簇索引`发生页面分裂和记录移位的情况,建议让主键拥有`AUTO_INCREMENT`属性
   - 7.定位并删除表中的重复和冗余索引
   - 8.尽量使用`覆盖索引`进行查询,避免`回表`带来的性能损耗

-- -



## 4.锁

- 加锁机制

  - 乐观锁
  - 悲观锁

- 兼容性

  - 共享锁
    - 读锁 - 相互不阻塞
    - 写锁 - 阻塞的,在一定时间内,只有一个请求能执行写入,并阻止其它锁读取正在写入的数据
  - 排他锁

- 锁粒度

  - 表锁
    - 开销小,加锁快
    - 锁定力度大,发生锁冲突概率高,并发度最低
    - 不会出现死锁
  - 行锁
    - 开销大,加锁慢
    - 会出现死锁
    - 锁定粒度小,发生锁冲突的概率低,并发度高
  - 页锁
    - 开销和加锁速度介于表锁和行锁之间
    - 会出现死锁
    - 锁定粒度介于表锁和行锁之间,并发度一般

- 锁模式

  - 记录锁(`Record Lock`)

    - 直接锁定某行记录

    - 触发时机

      - 当我们使用唯一性的索引(包括唯一索引和聚簇索引)进行 **等值查询** 且 **精准匹配** 到一条记录时,此时就会直接将这条记录锁定

      - ```sql
        SELECT * FROM table_name WHERE id = 6 FOR UPDATE;
        ```

      - 

  - 间隙锁(`Gap Lock`)

    - 指的是两个记录之间逻辑上尚未填入数据的部分,是一个**左开右开空间** `(x, y)`

    - 触发时机

      - 使用用 **等值查询** 或者 **范围查询**,并且没有命中任何一个`record`,此时就会将对应的间隙区间锁定

      - ```sql
        -- (1, 6)
        SELECT * FROM table_name WHERE id > 1 AND id < 6 FOR UPDATE;
        ```

      - 

  - 临键锁(`next-key Lock` )

    - `MySQL` 默认

    - 记录锁和间隙锁的结合

    - 临键指的是间隙加上它右边的记录组成的**左开右闭区间 (`(1, 6]`) **

    - 触发时机

      - 使用范围查询，并且命中了部分`record`记录，此时锁住的就是临键区间

      - ```sql
        -- [4, 7) & (7, +inf)
        SELECT * FROM table_name WHERE id > 5 AND id <= 7 FOR UPDATE;
        ```

      - 当使用唯一性索引,等值查询匹配到一条记录的时候,临键锁(`Next-Key Lock`)会退化成记录锁

      - 没有匹配到任何记录的时候,退化成间隙锁

  - 意向锁

    - 表锁
    - 为了支持 `InnoDB` 的多粒度锁,它解决的是表锁和行锁共存的问题
    - 当需要给一个表加表锁的时候,我们需要根据表中有没有数据行被锁定,以确定是否能加成功

  - 插入意向锁

    - 一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了意向锁 ,如果有的话,插入操作需要等待,直到拥有 `Gap` 锁的那个事务提交
    - 但是事务在等待的时候也需要在内存中生成一个锁结构,表明有事务想在某个 **间隙** 中插入新记录,但是现在在等待
      - 这种类型的锁命名为 `Insert Intention Locks`,也就是插入意向锁 



## 5.`ACID`

- 原子性(`Atomicity`)
  - `undo log`
- 一致性(`Consistency`)
- 隔离性(`Isolation`)
  - `MVCC`
- 持久性(`Durability`)
  - `redo log`



### 5.1.隔离级别

- 脏读(`Dirty Read`)：
  - 一个事务可以读取到另一个事务尚未提交的修
- 不可重复读(`Non-Repeatable Read`)
  - 同一个事务中,多次读取同一数据返回的结果不同
- 幻读(`Phantom Read`)
  - 一个事务中，两次查询返回不同的结果集(插入或删除)

-- -

- 读未提交(`Read Uncommitted`)
  - 允许脏读、不可重复读和幻读
- 读已提交(`Read Committed`)
  - 避免脏读,但允许不可重复读和幻读
- 可重复读(`Repeatable Read`)
  - 避免脏读和不可重复读,但允许幻读
  - 幻读
    - 在很大程度上减少了 **幻读** 问题
- 串行化(`Serializable`)



### 5.2.如何实现隔离级别

- 读未提交
  - 事务读不加锁,不阻塞其他事务的读和写
  - 事务写阻塞其他事务写,但不阻塞其他事务读
- 读已提交
  - 每次读取数据前都生成一个 `ReadView`
- 可重复读
  - 在第一次读取数据时生成一个 `ReadView`
- 串行化
  - 事务读写都加锁
  - 串行化的情况下，对于同一行事务,`写`会加`写锁`,`读`会加`读锁`。
  - 当出现读写锁冲突的时候,后访问的事务必须等前一个事务执行完成,才能继续执行



### 5.3.`MVCC`

通过维护数据历史版本,从而解决并发访问情况下的读一致性问题. 关键点: **隐式字段、undo 日志、版本链、快照读&当前读、Read View**

#### 5.3.1.`InnoDB`

##### 隐藏字段

- `DB_TRX_ID`
  - 事务 `ID`,每次修改时,都会把该事务的 `ID` 赋值给 `DB_TRX_ID`
- `DB_ROLL_PTR`
  - 回滚指针
  - 指向回滚段的 `undo` 日志

##### `Read View`

 就是事务执行 **快照读** 时,产生的读视图,相当于某时刻表记录的一个快照

- `m_ids`
- `min_trx_id`
- `max_trx_id`
- `creator_trx_id`

判断规则

- 如果被访问版本的 `DB_TRX_ID` 属性值与 `ReadView` 中的 `creator_trx_id` 值相同,意味着当前事务在访问它自己修改过的记录,所以该版本可以被当前事务访问
- 如果被访问版本的 `DB_TRX_ID` 属性值小于 `ReadView` 中的 `min_trx_id` 值,表明生成该版本的事务在当前事务生成 `ReadView` 前已经提交,所以该版本可以被当前事务访问
- 如果被访问版本的 `DB_TRX_ID` 属性值大于 `ReadView` 中的 `max_trx_id` 值,表明生成该版本的事务在当前事务生成 `ReadView` 后才开启,所以该版本不可以被当前事务访问
- 如果被访问版本的 `DB_TRX_ID` 属性值在 `ReadView` 的 `min_trx_id` 和 `max_trx_id` 之间,那就需要判断一下 `trx_id` 属性值是不是在 `m_ids` 列表中
  - 如果在,说明创建 `ReadView` 时生成该版本的事务还是活跃的,该版本不可以被访问
  - 如果不在，说明创建 `ReadView` 时生成该版本的事务已经被提交，该版本可以被访问



## 6.读写分离

> 读写分离的基本原理是将数据库读写操作分散到不同的节点上.

- 数据库服务器搭建主从集群(一主一从、一主多从…)
- 数据库主机负责读写操作,从机只负责读操作
- 数据库主机通过复制将数据同步到从机,每台数据库服务器都存储了所有的业务数据
- 业务服务器将写操作发给数据库主机,将读操作发给数据库从机



## 7.主从复制

- `master` 数据写入,更新 `binlog`
- `master` 创建一个 `dump` 线程向 `slave` 推送 `binlog`
- `slave` 连接到 `master` 的时候，会创建一个 `IO` 线程接收 `binlog`,并记录到 `relay log` 中继日志中
- `slave` 再开启一个 `SQL` 线程读取 `relay log` 事件并在 `slave` 执行,完成同步
- `slave` 记录自己的 `binlog`



### 7.1.分表方式

- 水平分表
  - 范围路由
  - `Hash` 路由
  - 配置路由
- 垂直分表



### 7.2.不停机扩容

- 阶段一
  - 在线双写,查询走老库
    - 建立好新的库表结构,数据写入旧库的同时,也写入拆分的新库
    - 数据迁移,使用数据迁移程序,将旧库中的历史数据迁移到新库
    - 使用定时任务,新旧库的数据对比,把差异补齐
- 阶段二
  - 在线双写,查询走新库
    - 完成了历史数据的同步和校验
    - 把对数据的读切换到新库
- 阶段三
  - 旧库下线
    - 旧库不再写入新的数据
    - 经过一段时间,确定旧库没有请求之后,就可以下线老库



-- -



## 8.`MySQL` 日志

- 错误日志
- 慢查询日志
- 事务日志
  - `redo log`
  - `undo log`
- 二进制日志
  - `binlog`



## 常用日志

- `binlog`

  - `binlog` 是逻辑日志,记录内容是语句的原始逻辑,类似于 **给 ID=2 这一行的 c 字段加 1** `MySQL Server` 层

  - 不管用什么存储引擎,只要发生了表数据更新,都会产生 `binlog` 日志

  - `MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`,需要依靠`binlog `来同步数据,保证数据一致性

  - `binlog`会记录所有涉及更新数据的逻辑操作,并且是顺序写

  - `binlog`的写入时机也非常简单,事务执行过程中,先把日志写到`binlog cache`,事务提交的时候再把`binlog cache` 写到 `binlog` 文件中

    - `page cache -> fsync -> binlog`

  - 一个事务的`binlog`不能被拆开,无论这个事务多大,也要确保一次性写入,所以系统会给每个线程分配一个块内存作为`binlog cache`

  - 可以通过`binlog_cache_size`参数控制单个线程 `binlog cache` 大小,如果存储内容超过了这个参数,就要暂存到磁盘(`Swap`)

  - 刷盘时机 `sync_binlog`

    - 0 
      - 表示每次提交事务都只`write`(`page cache`),由系统自行判断什么时候执行`fsync`
    - 1
      -  表示每次提交事务都会执行`fsync`
    - N (N > 1)
      - 表示每次提交事务都`write`,但累积`N`个事务后才`fsync`

  - 格式(`binlog_format` 参数设置)

    - `statement`

      - `SQL` 原文

      - ```sql
        UPDATE table_name SET update_time = NOW() WHERE id = 1;
        
        -- NOW() 导致数据与源库不一致
        ```

      - 

    - `row`

      - `SQL` 原文 + 具体数据

    - `mixed`

      -  `MySQL`会判断这条`SQL`语句是否可能引起数据不一致,如果是,就用`row`格式,否则就用`statement`格式

- `redo log`

  - `redo log` 它是物理日志,记录内容是 **在某个数据页上做了什么修改**,属于 `InnoDB` 存储引擎
  - 是`InnoDB`存储引擎独有的, 它让`MySQL`拥有了崩溃恢复能力
  - 每条 `redo log` 记录由 **表空间号+数据页号+偏移量+修改数据长度+具体修改的数据** 组成
  - 日志文件组(4)
    - `ib_logfile_x1`
    - …
    - `ib_logfile_4`
    - `write pos`
      - 是当前记录的位置,一边写一边后移
    - `checkpoint`
      - 是当前要擦除的位置,也是往后推移
    - 每次 `MySQL` 加载**日志文件组**恢复数据时,会清空加载过的 `redo log` 记录,并把 `checkpoint` 后移更新
    - `write pos` 和 `checkpoint` 之间的还空着的部分可以用来写入新的 `redo log` 记录
    - version
      - `8.0.30`
        - `innodb_log_files_in_group`
        - `innodb_log_file_size`
      - `8.0.3x`
        - `innodb_redo_log_capacity`
        - 固定: 32
        - 文件大小 `innodb_redo_log_capacity / 32`

- `undo log`

  -  所有事务进行的修改都会先记录到这个回滚日志中,然后再执行相关的操作
  - 如果执行过程中遇到异常的话,我们直接利用其回滚记录
  - `MVCC`
    - 隐藏字段
    - `Read View`
    - `undo log`
    - `InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性
      - 如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本
      - 每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改



总结

`MySQL` `InnoDB` 引擎

- 使用 **redo log(重做日志)** 保证事务的**持久性**
- 使用 **undo log(回滚日志)** 来保证事务的**原子性**
-  `MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性

-- -

**比较**

- `redo log`(重做日志) 让`InnoDB`存储引擎拥有了崩溃恢复能力
-  `binlog`(归档日志) 保证了`MySQL`集群架构的数据一致性
- 虽然它们都属于持久化的保证,但是侧重点不同
  -  在执行更新语句过程,会记录`redo log`与`binlog`两块日志,以基本的事务为单位
  - `redo log`在**事务执行过程中**可以**不断写入**
  - `binlog`只有在**提交事务**时才写入
  - 所以`redo log`与`binlog`的写入时机不一样

-- -

**两阶段提交**

- 开始事务
- 更新数据
- ⭐预写 - `redo log`
- 提交事务
- 写入 `binlog`
- ⭐提交 - `redo log`
  - 1.如果 `binlog` 失败
    - 写入`binlog`时发生异常也不会有影响
    - 因为`MySQL`根据`redo log`日志恢复数据时,发现`redo log`还处于`prepare`阶段,并且没有对应`binlog`日志,就会回滚该事务
    - `MySQL` 重启
      - 1.是否 `commit` 阶段
        - Y - 提交事务 - 恢复数据
        - N
        - 2.是否存在 `binlog`
          - Y - 提交事务 - 恢复数据
          - N - 回滚事务
  - 2.如果 `commit` 失败
    - `binlog` 已经存在 -> `MySQL` 认为是完整数据 -> 提交事务 - 恢复数据

-- -

`InnoDB` 刷新重做日志(`redo log`)的时机

`InnoDB` 在多种情况下会刷新重做日志,以保证数据的持久性和一致性

- 事务提交
  - 当事务提交时 `log buffer` 里的 `redo log` 会被刷新到磁盘(可以通过`innodb_flush_log_at_trx_commit`参数控制)
    - 0 - 表示每次事务提交时不进行刷盘操作
      - 这种方式性能最高,但是也最不安全,因为如果 `MySQL` 挂了或宕机了,可能会丢失最近 1 秒内的事务
    - 1 - 表示每次事务提交时都将进行刷盘操作
      - 默认
      - 这种方式性能最低,但是也最安全,因为只要事务提交成功, `redo log` 记录就一定在磁盘里,不会有任何数据丢失
    - 2 - 表示每次事务提交时都只把 `log buffer` 里的 `redo log` 内容写入 `page cache`(文件系统缓存)。`page cache` 是专门用来缓存文件的,这里被缓存的文件就是 `redo log` 文件
      - 这种方式的性能和安全性都介于前两者中间
- `log buffer` 空间不足
  - `log buffer` 中缓存的 `redo log` 已经占满了 `log buffer` 总容量(`innodb_log_buffer_size`)的大约一半左右,就需要把这些日志刷新到磁盘上
- 事务日志缓冲区写满
  - `InnoDB` 使用一个事务日志缓冲区(`transaction log buffer`)来暂时存储事务的重做日志条目。当缓冲区满时，会触发日志的刷新，将日志写入磁盘
- `Checkpoint`
  - `InnoDB` 定期会执行检查点操作,将内存中的脏数据(已修改但尚未写入磁盘的数据)刷新到磁盘,并且会将相应的重做日志一同刷新,以确保数据的一致性
- 后台刷新线程
  - `InnoDB` 启动了一个后台线程,负责周期性(每隔 1 秒)地将脏页(已修改但尚未写入磁盘的数据页)刷新到磁盘,并将相关的重做日志一同刷新
- 正常关闭服务器
  - `MySQL` 关闭的时候 `redo log` 都会刷入到磁盘里去



--- -

只要每次把修改后的数据页直接刷盘不就好了,还有 `redo log` 什么事？

- 数据页大小是`16KB`,盘比较耗时,可能就修改了数据页里的几 `Byte` 数据，有必要把完整的数据页刷盘吗？
- 数据页刷盘是随机写,因为一个数据页对应的位置可能在硬盘文件的随机位置,所以性能是很差
- 写 `redo log`,一行记录可能就占几十 `Byte`,只包含表**空间号+数据页号+磁盘文件偏移 量+更新值**,再加上是顺序写,所以刷盘速度很快